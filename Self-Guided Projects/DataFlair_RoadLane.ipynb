{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Road Lane Detection\n",
    "## (Self-Guided Project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## by Justin Sierchio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will be looking at road lane detections.\n",
    "\n",
    "This data is in .csv file format and is from DataFlair at: https://data-flair.training/blogs/road-lane-line-detection/. More information related to the dataset can be found at the same link.\n",
    "\n",
    "Note: this is a self-guided project following the tutorial provided the contributors at DataFlair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial libraries loaded into workspace!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.image as mpimg\n",
    "from moviepy.editor import VideoFileClip\n",
    "import math\n",
    "\n",
    "print('Initial libraries loaded into workspace!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, we are going to look at the road lanes where autonomous cars will run. We will be trying to detect white markings for the lanes by masking the rest of the frame. Each frame is a NumPy array of values and we will be converting those to 0. Once the lanes are detected, we will be using a Hough Transform (which detects rectangles, circles, triangles and lines. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by construction a function to apply frame masking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Function to Apply Frame Masking\n",
    "def interested_region(img, vertices):\n",
    "    if len(img.shape) > 2: \n",
    "        mask_color_ignore = (255,) * img.shape[2]\n",
    "    else:\n",
    "        mask_color_ignore = 255\n",
    "        \n",
    "    cv2.fillPoly(np.zeros_like(img), vertices, mask_color_ignore)\n",
    "    return cv2.bitwise_and(img, np.zeros_like(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will define a Hough Transform space to detect the lane lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Hough Transform function to Detect Lane Lines\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    lines_drawn(line_img,lines)\n",
    "    return line_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to actually draw the lines onto our picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Function to draw the lane lines\n",
    "def lines_drawn(img, lines, color=[255, 0, 0], thickness=6):\n",
    "    global cache\n",
    "    global first_frame\n",
    "    slope_l, slope_r = [],[]\n",
    "    lane_l,lane_r = [],[]\n",
    "    α =0.2 \n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            slope = (y2-y1)/(x2-x1)\n",
    "            if slope > 0.4:\n",
    "                slope_r.append(slope)\n",
    "                lane_r.append(line)\n",
    "            elif slope < -0.4:\n",
    "                slope_l.append(slope)\n",
    "                lane_l.append(line)\n",
    "        img.shape[0] = min(y1,y2,img.shape[0])\n",
    "    if((len(lane_l) == 0) or (len(lane_r) == 0)):\n",
    "        print ('no lane detected')\n",
    "        return 1\n",
    "    slope_mean_l = np.mean(slope_l,axis =0)\n",
    "    slope_mean_r = np.mean(slope_r,axis =0)\n",
    "    mean_l = np.mean(np.array(lane_l),axis=0)\n",
    "    mean_r = np.mean(np.array(lane_r),axis=0)\n",
    "    \n",
    "    if ((slope_mean_r == 0) or (slope_mean_l == 0 )):\n",
    "        print('dividing by zero')\n",
    "        return 1\n",
    "    \n",
    "    x1_l = int((img.shape[0] - mean_l[0][1] - (slope_mean_l * mean_l[0][0]))/slope_mean_l) \n",
    "    x2_l = int((img.shape[0] - mean_l[0][1] - (slope_mean_l * mean_l[0][0]))/slope_mean_l)   \n",
    "    x1_r = int((img.shape[0] - mean_r[0][1] - (slope_mean_r * mean_r[0][0]))/slope_mean_r)\n",
    "    x2_r = int((img.shape[0] - mean_r[0][1] - (slope_mean_r * mean_r[0][0]))/slope_mean_r)\n",
    "    \n",
    "   \n",
    "    if x1_l > x1_r:\n",
    "        x1_l = int((x1_l+x1_r)/2)\n",
    "        x1_r = x1_l\n",
    "        y1_l = int((slope_mean_l * x1_l ) + mean_l[0][1] - (slope_mean_l * mean_l[0][0]))\n",
    "        y1_r = int((slope_mean_r * x1_r ) + mean_r[0][1] - (slope_mean_r * mean_r[0][0]))\n",
    "        y2_l = int((slope_mean_l * x2_l ) + mean_l[0][1] - (slope_mean_l * mean_l[0][0]))\n",
    "        y2_r = int((slope_mean_r * x2_r ) + mean_r[0][1] - (slope_mean_r * mean_r[0][0]))\n",
    "    else:\n",
    "        y1_l = img.shape[0]\n",
    "        y2_l = img.shape[0]\n",
    "        y1_r = img.shape[0]\n",
    "        y2_r = img.shape[0]\n",
    "      \n",
    "    present_frame = np.array([x1_l,y1_l,x2_l,y2_l,x1_r,y1_r,x2_r,y2_r],dtype =\"float32\")\n",
    "    \n",
    "    if first_frame == 1:\n",
    "        next_frame = present_frame        \n",
    "        first_frame = 0        \n",
    "    else :\n",
    "        prev_frame = cache\n",
    "        next_frame = (1-α)*prev_frame+α*present_frame\n",
    "             \n",
    "    cv2.line(img, (int(next_frame[0]), int(next_frame[1])), (int(next_frame[2]),int(next_frame[3])), color, thickness)\n",
    "    cv2.line(img, (int(next_frame[4]), int(next_frame[5])), (int(next_frame[6]),int(next_frame[7])), color, thickness)\n",
    "    \n",
    "    cache = next_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now remember that we will need to process each frame of video - the lanes are not static from picture to picture. Hence, we need another function to take this observation into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a weighted image and processed image function set\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)\n",
    "def process_image(image):\n",
    "    global first_frame\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    img_hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    lower_yellow = np.array([20, 100, 100], dtype = \"uint8\")\n",
    "    upper_yellow = np.array([30, 255, 255], dtype=\"uint8\")\n",
    "    mask_yellow = cv2.inRange(img_hsv, lower_yellow, upper_yellow)\n",
    "    mask_white = cv2.inRange(gray_image, 200, 255)\n",
    "    mask_yw = cv2.bitwise_or(mask_white, mask_yellow)\n",
    "    mask_yw_image = cv2.bitwise_and(gray_image, mask_yw)\n",
    "    gauss_gray= cv2.GaussianBlur(mask_yw_image, (5, 5), 0)\n",
    "    canny_edges=cv2.Canny(gauss_gray, 50, 150)\n",
    "    imshape = image.shape\n",
    "    lower_left = [imshape[1]/9,imshape[0]]\n",
    "    lower_right = [imshape[1]-imshape[1]/9,imshape[0]]\n",
    "    top_left = [imshape[1]/2-imshape[1]/8,imshape[0]/2+imshape[0]/10]\n",
    "    top_right = [imshape[1]/2+imshape[1]/8,imshape[0]/2+imshape[0]/10]\n",
    "    vertices = [np.array([lower_left,top_left,top_right,lower_right],dtype=np.int32)]\n",
    "    roi_image = interested_region(canny_edges, vertices)\n",
    "    theta = np.pi/180\n",
    "    line_image = hough_lines(roi_image, 4, theta, 30, 100, 180)\n",
    "    result = weighted_img(line_image, image, α=0.8, β=1., λ=0.)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last part of the algorithm development will be to record the output image file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first_frame = 1\n",
    "#white_output = '__path_to_output_file__'\n",
    "#clip1 = VideoFileClip(\"__path_to_input_file__\")\n",
    "#white_clip = clip1.fl_image(process_image)\n",
    "#white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to find a video file to activate the last part of the code. In the meantime, let's construct the GUI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GUI Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by importing some additional libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional libraries loaded into workspace!\n"
     ]
    }
   ],
   "source": [
    "# Import additional libraries\n",
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "import cv2\n",
    "from PIL import Image, ImageTk\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "print('Additional libraries loaded into workspace!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start forming a GUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start forming a GUI\n",
    "global last_frame1                                   \n",
    "last_frame1 = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "global last_frame2                                      \n",
    "last_frame2 = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "global cap1\n",
    "global cap2\n",
    "cap1 = cv2.VideoCapture(\"path_to_input_test_video\")\n",
    "cap2 = cv2.VideoCapture(\"path_to_resultant_lane_detected_video\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a function to show the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to show the video\n",
    "def show_vid():                                       \n",
    "    if not cap1.isOpened():                             \n",
    "        print(\"cant open the camera1\")\n",
    "    flag1, frame1 = cap1.read()\n",
    "    frame1 = cv2.resize(frame1,(400,500))\n",
    "    if flag1 is None:\n",
    "        print (\"Major error!\")\n",
    "    elif flag1:\n",
    "        global last_frame1\n",
    "        last_frame1 = frame1.copy()\n",
    "        pic = cv2.cvtColor(last_frame1, cv2.COLOR_BGR2RGB)     \n",
    "        img = Image.fromarray(pic)\n",
    "        imgtk = ImageTk.PhotoImage(image=img)\n",
    "        lmain.imgtk = imgtk\n",
    "        lmain.configure(image=imgtk)\n",
    "        lmain.after(10, show_vid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to show the lane detection, we create a second function to show another video with the lanes detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second video function\n",
    "def show_vid2():\n",
    "    if not cap2.isOpened():                             \n",
    "        print(\"cant open the camera2\")\n",
    "    flag2, frame2 = cap2.read()\n",
    "    frame2 = cv2.resize(frame2,(400,500))\n",
    "    if flag2 is None:\n",
    "        print (\"Major error2!\")\n",
    "    elif flag2:\n",
    "        global last_frame2\n",
    "        last_frame2 = frame2.copy()\n",
    "        pic2 = cv2.cvtColor(last_frame2, cv2.COLOR_BGR2RGB)\n",
    "        img2 = Image.fromarray(pic2)\n",
    "        img2tk = ImageTk.PhotoImage(image=img2)\n",
    "        lmain2.img2tk = img2tk\n",
    "        lmain2.configure(image=img2tk)\n",
    "        lmain2.after(10, show_vid2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we create an if-then statement to show the actual lane detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show actual lane detection\n",
    "if __name__ == '__main__':\n",
    "    root=tk.Tk()                                     \n",
    "    lmain = tk.Label(master=root)\n",
    "    lmain2 = tk.Label(master=root)\n",
    "    lmain.pack(side = LEFT)\n",
    "    lmain2.pack(side = RIGHT)\n",
    "    root.title(\"Lane-line detection\")            \n",
    "    root.geometry(\"900x700+100+10\") \n",
    "    exitbutton = Button(root, text='Quit',fg=\"red\",command=   root.destroy).pack(side = BOTTOM,)\n",
    "    show_vid()\n",
    "    show_vid2()\n",
    "    root.mainloop()                                  \n",
    "    cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
